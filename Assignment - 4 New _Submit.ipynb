{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e17a55",
   "metadata": {},
   "source": [
    "# Assignment-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5511d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "af714cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "import time\n",
    "import requests\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import xlsxwriter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbb6f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=d8ca65cd9809dbd20c9299b2622ed28c9cf2e7dbc4700b357541ee3b853a9572\n",
      "  Stored in directory: c:\\users\\bhavith\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: requests in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhavith\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c3cc0",
   "metadata": {},
   "source": [
    "# Question -1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c857cb07",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank B) Name C) Artist D) Upload date E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9c9cf775",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c4a2028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7a0e514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "for i in ranks:\n",
    "    rank=i.text\n",
    "    Rank.append(rank)\n",
    "    \n",
    "names=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "for i in names:\n",
    "    name=i.text\n",
    "    Name.append(name)\n",
    "\n",
    "    \n",
    "artists=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "for i in artists:\n",
    "    art=i.text\n",
    "    Artist.append(art)\n",
    "    \n",
    "    \n",
    "upload_date=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "for i in upload_date:\n",
    "    date=i.text\n",
    "    Upload_date.append(date)\n",
    "    \n",
    "views=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "for i in views:\n",
    "    view=i.text\n",
    "    Views.append(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "915abdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Name),len(Artist),len(Upload_date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73aeb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_Rank</th>\n",
       "      <th>Video_Names</th>\n",
       "      <th>Video_Artist</th>\n",
       "      <th>Video_Published</th>\n",
       "      <th>Video_Viewa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[26]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[41]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[43]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[46]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"[47]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[50]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[51]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Video_Rank                                      Video_Names  \\\n",
       "0          1.                            \"Baby Shark Dance\"[6]   \n",
       "1          2.                                   \"Despacito\"[9]   \n",
       "2          3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3          4.                                  \"Bath Song\"[17]   \n",
       "4          5.                               \"Shape of You\"[18]   \n",
       "5          6.                              \"See You Again\"[21]   \n",
       "6          7.                \"Phonics Song with Two Words\"[26]   \n",
       "7          8.                          \"Wheels on the Bus\"[27]   \n",
       "8          9.                                \"Uptown Funk\"[28]   \n",
       "9         10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10        11.                              \"Gangnam Style\"[30]   \n",
       "11        12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12        13.                             \"Dame Tu Cosita\"[36]   \n",
       "13        14.                                     \"Axel F\"[37]   \n",
       "14        15.                                      \"Sugar\"[38]   \n",
       "15        16.                                       \"Roar\"[39]   \n",
       "16        17.                             \"Counting Stars\"[40]   \n",
       "17        18.                                      \"Sorry\"[41]   \n",
       "18        19.                        \"Baa Baa Black Sheep\"[42]   \n",
       "19        20.                          \"Thinking Out Loud\"[43]   \n",
       "20        21.           \"Waka Waka (This Time for Africa)\"[44]   \n",
       "21        22.                                 \"Dark Horse\"[45]   \n",
       "22        23.                             \"Lakdi Ki Kathi\"[46]   \n",
       "23        24.                                      \"Faded\"[47]   \n",
       "24        25.                                    \"Perfect\"[48]   \n",
       "25        26.                                 \"Let Her Go\"[49]   \n",
       "26        27.                             \"Girls Like You\"[50]   \n",
       "27        28.          \"Humpty the train on a fruits ride\"[51]   \n",
       "28        29.                                    \"Lean On\"[52]   \n",
       "29        30.                                   \"Bailando\"[53]   \n",
       "\n",
       "                                     Video_Artist    Video_Published  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                     Crazy Frog      June 16, 2009   \n",
       "14                                       Maroon 5   January 14, 2015   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "19                                     Ed Sheeran    October 7, 2014   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                   Jingle Toons      June 14, 2018   \n",
       "23                                    Alan Walker   December 3, 2015   \n",
       "24                                     Ed Sheeran   November 9, 2017   \n",
       "25                                      Passenger      July 25, 2012   \n",
       "26                                       Maroon 5       May 31, 2018   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "28                                    Major Lazer     March 22, 2015   \n",
       "29                               Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Video_Viewa  \n",
       "0        12.85  \n",
       "1         8.16  \n",
       "2         6.70  \n",
       "3         6.20  \n",
       "4         6.00  \n",
       "5         5.89  \n",
       "6         5.30  \n",
       "7         5.24  \n",
       "8         4.92  \n",
       "9         4.89  \n",
       "10        4.80  \n",
       "11        4.55  \n",
       "12        4.35  \n",
       "13        3.91  \n",
       "14        3.87  \n",
       "15        3.80  \n",
       "16        3.79  \n",
       "17        3.66  \n",
       "18        3.64  \n",
       "19        3.60  \n",
       "20        3.59  \n",
       "21        3.52  \n",
       "22        3.48  \n",
       "23        3.45  \n",
       "24        3.45  \n",
       "25        3.44  \n",
       "26        3.42  \n",
       "27        3.41  \n",
       "28        3.38  \n",
       "29        3.38  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "\n",
    "df['Video_Rank']= Rank\n",
    "df['Video_Names'] =Name\n",
    "df['Video_Artist'] =Artist\n",
    "df['Video_Published'] =Upload_date\n",
    "df['Video_Viewa'] =Views\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651ca43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87117f2e",
   "metadata": {},
   "source": [
    "# Question-2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89a1f470",
   "metadata": {},
   "source": [
    "Scrape the details teamIndia’sinternationalfixtures from bcci.tv \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5db96502",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https://www.bcci.tv/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31dadf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on international\n",
    "international=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]')\n",
    "international.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7e9df555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on fixtures\n",
    "fixtures= driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div/ul/li[1]\")\n",
    "fixtures.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aebe79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty list\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1bd838b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>16 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>19 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>22 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>West Indies\\nvs\\nIndia</td>\n",
       "      <td>Kensington Oval,</td>\n",
       "      <td>27 JUL 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>West Indies\\nvs\\nIndia</td>\n",
       "      <td>Kensington Oval,</td>\n",
       "      <td>29 JUL 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>West Indies\\nvs\\nIndia</td>\n",
       "      <td>Brian Lara Stadium,</td>\n",
       "      <td>1 AUG 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>India\\nvs\\nAfghanistan</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_title                             Series  \\\n",
       "0   1st ODI -  Bangladesh Women\\nvs\\nIndia Women   \n",
       "1   2nd ODI -  Bangladesh Women\\nvs\\nIndia Women   \n",
       "2   3rd ODI -  Bangladesh Women\\nvs\\nIndia Women   \n",
       "3   1st ODI -             West Indies\\nvs\\nIndia   \n",
       "4   2nd ODI -             West Indies\\nvs\\nIndia   \n",
       "5   3rd ODI -             West Indies\\nvs\\nIndia   \n",
       "6   1st ODI -               India\\nvs\\nAustralia   \n",
       "7   2nd ODI -             India\\nvs\\nAfghanistan   \n",
       "\n",
       "                                    Place         Date         Time  \n",
       "0  Shere Bangla National Stadium, Mirpur,  16 JUL 2023  9:00 AM IST  \n",
       "1  Shere Bangla National Stadium, Mirpur,  19 JUL 2023  9:00 AM IST  \n",
       "2  Shere Bangla National Stadium, Mirpur,  22 JUL 2023  9:00 AM IST  \n",
       "3                        Kensington Oval,  27 JUL 2023  7:00 PM IST  \n",
       "4                        Kensington Oval,  29 JUL 2023  7:00 PM IST  \n",
       "5                     Brian Lara Stadium,   1 AUG 2023  7:00 PM IST  \n",
       "6                 MA Chidambaram Stadium,   8 OCT 2023  2:00 PM IST  \n",
       "7                   Arun Jaitley Stadium,  11 OCT 2023  2:00 PM IST  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Match_title\n",
    "match_title= driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in match_title:\n",
    "    Match_title.append(i.text)\n",
    "    \n",
    "#Scraping Series\n",
    "series= driver.find_elements(By.XPATH,'//div[@class=\"match-card-middle__inner d-flex justify-content-between\"]')\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "    \n",
    "#Scraping Place\n",
    "place= driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in place:\n",
    "    Place.append(i.text)   \n",
    "    \n",
    "#Scraping Date\n",
    "date= driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date:\n",
    "    Date.append(i.text)   \n",
    "    \n",
    "#Scraping Time\n",
    "time= driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time:\n",
    "    Time.append(i.text) \n",
    "\n",
    "Fixture=pd.DataFrame({})\n",
    "Fixture['Match_title']=Match_title\n",
    "Fixture['Series']=Series\n",
    "Fixture['Place']=Place\n",
    "Fixture['Date']=Date\n",
    "Fixture['Time']=Time\n",
    "Fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf344a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02f12234",
   "metadata": {},
   "source": [
    "# Question-3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aa77281",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99591115",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"http://statisticstimes.com/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "288b7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click Economy\n",
    "Economy=driver.find_element(By.XPATH,'//div[@id=\"top\"]/div[2]/div[2]/button')\n",
    "Economy.click()\n",
    "\n",
    "#Click India\n",
    "India= driver.find_element(By.XPATH,'//div[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "India.click()\n",
    "\n",
    "#Click on India GPD\n",
    "GDP=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]')\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "859eb7e0",
   "metadata": {},
   "source": [
    "GDP=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]')\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "92fc462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_at_current_price_19_20</th>\n",
       "      <th>GSDP_at_current_price_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_at_current_price_19_20  \\\n",
       "0     1                Maharashtra                           -   \n",
       "1     2                 Tamil Nadu                   1,845,853   \n",
       "2     3              Uttar Pradesh                   1,687,818   \n",
       "3     4                    Gujarat                           -   \n",
       "4     5                  Karnataka                   1,631,977   \n",
       "5     6                West Bengal                   1,253,832   \n",
       "6     7                  Rajasthan                   1,020,989   \n",
       "7     8             Andhra Pradesh                     972,782   \n",
       "8     9                  Telangana                     969,604   \n",
       "9    10             Madhya Pradesh                     906,672   \n",
       "10   11                     Kerala                           -   \n",
       "11   12                      Delhi                     856,112   \n",
       "12   13                    Haryana                     831,610   \n",
       "13   14                      Bihar                     611,804   \n",
       "14   15                     Punjab                     574,760   \n",
       "15   16                     Odisha                     521,275   \n",
       "16   17                      Assam                           -   \n",
       "17   18               Chhattisgarh                     329,180   \n",
       "18   19                  Jharkhand                     328,598   \n",
       "19   20                Uttarakhand                           -   \n",
       "20   21            Jammu & Kashmir                           -   \n",
       "21   22           Himachal Pradesh                     165,472   \n",
       "22   23                        Goa                      80,449   \n",
       "23   24                    Tripura                      55,984   \n",
       "24   25                 Chandigarh                           -   \n",
       "25   26                 Puducherry                      38,253   \n",
       "26   27                  Meghalaya                      36,572   \n",
       "27   28                     Sikkim                      32,496   \n",
       "28   29                    Manipur                      31,790   \n",
       "29   30                   Nagaland                           -   \n",
       "30   31          Arunachal Pradesh                           -   \n",
       "31   32                    Mizoram                      26,503   \n",
       "32   33  Andaman & Nicobar Islands                           -   \n",
       "\n",
       "   GSDP_at_current_price_18_19 Share_18_19 GDP_billion  \n",
       "0                    2,632,792      13.94%     399.921  \n",
       "1                    1,630,208       8.63%     247.629  \n",
       "2                    1,584,764       8.39%     240.726  \n",
       "3                    1,502,899       7.96%     228.290  \n",
       "4                    1,493,127       7.91%     226.806  \n",
       "5                    1,089,898       5.77%     165.556  \n",
       "6                      942,586       4.99%     143.179  \n",
       "7                      862,957       4.57%     131.083  \n",
       "8                      861,031       4.56%     130.791  \n",
       "9                      809,592       4.29%     122.977  \n",
       "10                     781,653       4.14%     118.733  \n",
       "11                     774,870       4.10%     117.703  \n",
       "12                     734,163       3.89%     111.519  \n",
       "13                     530,363       2.81%      80.562  \n",
       "14                     526,376       2.79%      79.957  \n",
       "15                     487,805       2.58%      74.098  \n",
       "16                     315,881       1.67%      47.982  \n",
       "17                     304,063       1.61%      46.187  \n",
       "18                     297,204       1.57%      45.145  \n",
       "19                     245,895       1.30%      37.351  \n",
       "20                     155,956       0.83%      23.690  \n",
       "21                     153,845       0.81%      23.369  \n",
       "22                      73,170       0.39%      11.115  \n",
       "23                      49,845       0.26%       7.571  \n",
       "24                      42,114       0.22%       6.397  \n",
       "25                      34,433       0.18%       5.230  \n",
       "26                      33,481       0.18%       5.086  \n",
       "27                      28,723       0.15%       4.363  \n",
       "28                      27,870       0.15%       4.233  \n",
       "29                      27,283       0.14%       4.144  \n",
       "30                      24,603       0.13%       3.737  \n",
       "31                      22,287       0.12%       3.385  \n",
       "32                           -           -           -  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating empty list\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_at_current_price_19_20=[]\n",
    "GSDP_at_current_price_18_19=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "#Scraping Rank\n",
    "rank= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    if i.text is None:\n",
    "        Rank.append('--')\n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "        \n",
    "#Scraping State\n",
    "state= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "for i in state:\n",
    "    if i.text is None:\n",
    "        State.append('--')\n",
    "    else:\n",
    "        State.append(i.text)\n",
    "                \n",
    "#Scraping GSDP_at_current_price_19_20\n",
    "gSDP_at_current_price_19_20= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "for i in gSDP_at_current_price_19_20:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_19_20.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_19_20.append(i.text)\n",
    "        \n",
    "#Scraping GSDP_at_current_price_18_19\n",
    "gSDP_at_current_price_18_19= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "for i in gSDP_at_current_price_18_19:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_18_19.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_18_19.append(i.text)\n",
    "        \n",
    "#Scraping Share_18_19\n",
    "share_18_19= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "for i in share_18_19:\n",
    "    if i.text is None:\n",
    "        Share_18_19.append('--')\n",
    "    else:\n",
    "        Share_18_19.append(i.text)\n",
    "        \n",
    "#Scraping GDP_billion\n",
    "gDP_billion= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "for i in gDP_billion:\n",
    "    if i.text is None:\n",
    "        GDP_billion.append('--')\n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        \n",
    "# creating dataframe\n",
    "GDP_India=pd.DataFrame({})\n",
    "GDP_India['Rank']=Rank\n",
    "GDP_India['State']=State\n",
    "GDP_India['GSDP_at_current_price_19_20']=GSDP_at_current_price_19_20\n",
    "GDP_India['GSDP_at_current_price_18_19']=GSDP_at_current_price_18_19\n",
    "GDP_India['Share_18_19']=Share_18_19\n",
    "GDP_India['GDP_billion']=GDP_billion\n",
    "GDP_India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9f4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d09b491",
   "metadata": {},
   "source": [
    "# Question-4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d943ebe4",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c4aa71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https://github.com/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91a9ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explore=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[1]/deferred-side-panel/div/modal-dialog/div[3]/nav/nav-list/ul/li[1]/a/span[2]')\n",
    "Explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5f55b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "Treading=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]')\n",
    "Treading.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6a25e5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChaoningZhang / MobileSAM</td>\n",
       "      <td>This is the offiicial code for Faster Segment ...</td>\n",
       "      <td>301</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramonvc / freegpt-webui</td>\n",
       "      <td>GPT 3.5/4 with a Chat Web UI. No API key requi...</td>\n",
       "      <td>557</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THUDM / ChatGLM2-6B</td>\n",
       "      <td>ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语...</td>\n",
       "      <td>1,077</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PowerShell / PowerShell</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>6,844</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XingangPan / DragGAN</td>\n",
       "      <td>Official Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "      <td>2,855</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hiyouga / ChatGLM-Efficient-Tuning</td>\n",
       "      <td>Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效...</td>\n",
       "      <td>219</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>5,236</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THUDM / ChatGLM-6B</td>\n",
       "      <td>ChatGLM-6B: An Open Bilingual Dialogue Languag...</td>\n",
       "      <td>4,028</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>practical-tutorials / project-based-learning</td>\n",
       "      <td>Curated list of project-based tutorials</td>\n",
       "      <td>15,100</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sohamkamani / javascript-design-patterns-for-h...</td>\n",
       "      <td>An ultra-simplified explanation of design patt...</td>\n",
       "      <td>468</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>papers-we-love / papers-we-love</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "      <td>5,525</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cvg / LightGlue</td>\n",
       "      <td>LightGlue: Local Feature Matching at Light Speed</td>\n",
       "      <td>73</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>turboderp / exllama</td>\n",
       "      <td>A more memory-efficient rewrite of the HF tran...</td>\n",
       "      <td>109</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fuqiuluo / unidbg-fetch-qsign</td>\n",
       "      <td>获取QQSign通过Unidbg</td>\n",
       "      <td>82</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jasontaylordev / CleanArchitecture</td>\n",
       "      <td>Clean Architecture Solution Template for ASP.N...</td>\n",
       "      <td>2,801</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>toeverything / AFFiNE</td>\n",
       "      <td>There can be more than Notion and Miro. AFFiNE...</td>\n",
       "      <td>903</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ripienaar / free-for-dev</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>7,745</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>55,913</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chat2db / Chat2DB</td>\n",
       "      <td>🔥 🔥 🔥 An intelligent and versatile general-pur...</td>\n",
       "      <td>461</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PlexPt / awesome-chatgpt-prompts-zh</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>12,683</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>labmlai / annotated_deep_learning_paper_implem...</td>\n",
       "      <td>🧑‍🏫 59 Implementations/tutorials of deep learn...</td>\n",
       "      <td>2,811</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>microsoft / Web-Dev-For-Beginners</td>\n",
       "      <td>24 Lessons, 12 Weeks, Get Started as a Web Dev...</td>\n",
       "      <td>11,301</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dragonflydb / dragonfly</td>\n",
       "      <td>A modern replacement for Redis and Memcached</td>\n",
       "      <td>712</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wgwang / LLMs-In-China</td>\n",
       "      <td>中国大模型</td>\n",
       "      <td>77</td>\n",
       "      <td>Built by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>StanGirard / quivr</td>\n",
       "      <td>🧠 Dump all your files into your private Genera...</td>\n",
       "      <td>1,124</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository_title  \\\n",
       "0                           ChaoningZhang / MobileSAM   \n",
       "1                             ramonvc / freegpt-webui   \n",
       "2                                 THUDM / ChatGLM2-6B   \n",
       "3                             PowerShell / PowerShell   \n",
       "4                                XingangPan / DragGAN   \n",
       "5                  hiyouga / ChatGLM-Efficient-Tuning   \n",
       "6                                    facebook / folly   \n",
       "7                                  THUDM / ChatGLM-6B   \n",
       "8        practical-tutorials / project-based-learning   \n",
       "9   sohamkamani / javascript-design-patterns-for-h...   \n",
       "10                    papers-we-love / papers-we-love   \n",
       "11                                    cvg / LightGlue   \n",
       "12                                turboderp / exllama   \n",
       "13                      fuqiuluo / unidbg-fetch-qsign   \n",
       "14                 jasontaylordev / CleanArchitecture   \n",
       "15                              toeverything / AFFiNE   \n",
       "16                           ripienaar / free-for-dev   \n",
       "17           EbookFoundation / free-programming-books   \n",
       "18                                  chat2db / Chat2DB   \n",
       "19                PlexPt / awesome-chatgpt-prompts-zh   \n",
       "20  labmlai / annotated_deep_learning_paper_implem...   \n",
       "21                  microsoft / Web-Dev-For-Beginners   \n",
       "22                            dragonflydb / dragonfly   \n",
       "23                             wgwang / LLMs-In-China   \n",
       "24                                 StanGirard / quivr   \n",
       "\n",
       "                               Repository_description Contributors_count  \\\n",
       "0   This is the offiicial code for Faster Segment ...                301   \n",
       "1   GPT 3.5/4 with a Chat Web UI. No API key requi...                557   \n",
       "2   ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语...              1,077   \n",
       "3                        PowerShell for every system!              6,844   \n",
       "4           Official Code for DragGAN (SIGGRAPH 2023)              2,855   \n",
       "5   Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效...                219   \n",
       "6   An open-source C++ library developed and used ...              5,236   \n",
       "7   ChatGLM-6B: An Open Bilingual Dialogue Languag...              4,028   \n",
       "8             Curated list of project-based tutorials             15,100   \n",
       "9   An ultra-simplified explanation of design patt...                468   \n",
       "10  Papers from the computer science community to ...              5,525   \n",
       "11   LightGlue: Local Feature Matching at Light Speed                 73   \n",
       "12  A more memory-efficient rewrite of the HF tran...                109   \n",
       "13                                   获取QQSign通过Unidbg                 82   \n",
       "14  Clean Architecture Solution Template for ASP.N...              2,801   \n",
       "15  There can be more than Notion and Miro. AFFiNE...                903   \n",
       "16  A list of SaaS, PaaS and IaaS offerings that h...              7,745   \n",
       "17               📚 Freely available programming books             55,913   \n",
       "18  🔥 🔥 🔥 An intelligent and versatile general-pur...                461   \n",
       "19                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。             12,683   \n",
       "20  🧑‍🏫 59 Implementations/tutorials of deep learn...              2,811   \n",
       "21  24 Lessons, 12 Weeks, Get Started as a Web Dev...             11,301   \n",
       "22       A modern replacement for Redis and Memcached                712   \n",
       "23                                              中国大模型                 77   \n",
       "24  🧠 Dump all your files into your private Genera...              1,124   \n",
       "\n",
       "       Language_used  \n",
       "0   Jupyter Notebook  \n",
       "1             Python  \n",
       "2             Python  \n",
       "3                 C#  \n",
       "4             Python  \n",
       "5             Python  \n",
       "6                C++  \n",
       "7             Python  \n",
       "8           Built by  \n",
       "9           Built by  \n",
       "10             Shell  \n",
       "11  Jupyter Notebook  \n",
       "12            Python  \n",
       "13            Kotlin  \n",
       "14                C#  \n",
       "15        TypeScript  \n",
       "16              HTML  \n",
       "17          Built by  \n",
       "18              Java  \n",
       "19          Built by  \n",
       "20  Jupyter Notebook  \n",
       "21        JavaScript  \n",
       "22               C++  \n",
       "23          Built by  \n",
       "24        TypeScript  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating emplty list \n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "#scraping Repository_title\n",
    "repository_title=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in repository_title:\n",
    "    if i.text is None:\n",
    "        Repository_title.append('--')\n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "        \n",
    "#scraping Repository_description\n",
    "repository_description=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in repository_description:\n",
    "    if i.text is None:\n",
    "        Repository_description.append('--')\n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Contributors_count\n",
    "contributors_count=driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/a[2]')\n",
    "for i in contributors_count:\n",
    "    if i.text is None:\n",
    "        Contributors_count.append('--')\n",
    "    else:\n",
    "        Contributors_count.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Language_used\n",
    "language_used=driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/span[1]')\n",
    "for i in language_used:\n",
    "    if i.text is None:\n",
    "        Language_used.append('--')\n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "        \n",
    "Treding_rep=pd.DataFrame({})\n",
    "Treding_rep['Repository_title']= Repository_title\n",
    "Treding_rep['Repository_description']= Repository_description\n",
    "Treding_rep['Contributors_count']= Contributors_count\n",
    "Treding_rep['Language_used']= Language_used\n",
    "Treding_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a3717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9593db69",
   "metadata": {},
   "source": [
    "# Question-5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb182f9",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3ef960da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https:/www.billboard.com/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3d92c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on option button\n",
    "charts=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bea93a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hot_song= driver.find_element(By.XPATH,'//span[@class=\"c-label  \"][1]')\n",
    "Hot_song.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0a17d254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Angel, Pt. 1</td>\n",
       "      <td>Kodak Black, NLE Choppa, Jimin, JVKE &amp; Muni Long</td>\n",
       "      <td>-</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>Parmalee</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Moonlight</td>\n",
       "      <td>Kali Uchis</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Classy 101</td>\n",
       "      <td>Feid x Young Miko</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bluffin</td>\n",
       "      <td>Gucci Mane &amp; Lil Baby</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song_name                                       Artist_name  \\\n",
       "0     Last Night                                     Morgan Wallen   \n",
       "1       Fast Car                                        Luke Combs   \n",
       "2      Calm Down                               Rema & Selena Gomez   \n",
       "3        Flowers                                       Miley Cyrus   \n",
       "4    All My Life                        Lil Durk Featuring J. Cole   \n",
       "..           ...                                               ...   \n",
       "95  Angel, Pt. 1  Kodak Black, NLE Choppa, Jimin, JVKE & Muni Long   \n",
       "96  Girl In Mine                                          Parmalee   \n",
       "97     Moonlight                                        Kali Uchis   \n",
       "98    Classy 101                                 Feid x Young Miko   \n",
       "99       Bluffin                             Gucci Mane & Lil Baby   \n",
       "\n",
       "   Last_week_rank Peak_rank Weeks_on_board  \n",
       "0               1         1             21  \n",
       "1               3         2             13  \n",
       "2               4         3             42  \n",
       "3               2         1             23  \n",
       "4               5         2              6  \n",
       "..            ...       ...            ...  \n",
       "95              -        65              2  \n",
       "96              -        97              1  \n",
       "97             90        80             11  \n",
       "98              -        99              1  \n",
       "99              -       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Blank List\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "#Scraping Song_name\n",
    "song_name= driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')\n",
    "for i in song_name:\n",
    "    if i.text is None:\n",
    "        Song_name.append('--')\n",
    "    else:\n",
    "        Song_name.append(i.text)\n",
    "\n",
    "#Scraping Artist_name\n",
    "artist_name= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/span')\n",
    "for i in artist_name:\n",
    "    if i.text is None:\n",
    "        Artist_name.append('--')\n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "        \n",
    "#Scraping Last_week_rank\n",
    "last_week_rank= driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li/ul/li[4]/span')\n",
    "for i in last_week_rank:\n",
    "    if i.text is None:\n",
    "        Last_week_rank.append('--')\n",
    "    else:\n",
    "        Last_week_rank.append(i.text)\n",
    "        \n",
    "#Scraping Peak_rank\n",
    "peak_rank= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[5]/span')\n",
    "for i in peak_rank:\n",
    "    if i.text is None:\n",
    "        Peak_rank.append('--')\n",
    "    else:\n",
    "        Peak_rank.append(i.text)\n",
    "        \n",
    "#Scraping Weeks_on_board\n",
    "weeks_on_board= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[6]/span')\n",
    "for i in weeks_on_board:\n",
    "    if i.text is None:\n",
    "        Weeks_on_board.append('--')\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "Hot_Songs=pd.DataFrame({})\n",
    "Hot_Songs['Song_name']=Song_name\n",
    "Hot_Songs['Artist_name']=Artist_name\n",
    "Hot_Songs['Last_week_rank']=Last_week_rank\n",
    "Hot_Songs['Peak_rank']=Peak_rank\n",
    "Hot_Songs['Weeks_on_board']=Weeks_on_board\n",
    "\n",
    "Hot_Songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93250f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aba740b",
   "metadata": {},
   "source": [
    "# Question-6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4adb4381",
   "metadata": {},
   "source": [
    "6.Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5a5ea8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "da4dc090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "# Scraping Book_name\n",
    "book_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in book_name:\n",
    "    if i.text is None:\n",
    "        Book_name.append('--')\n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "author_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in author_name:\n",
    "    if i.text is None:\n",
    "        Author_name.append('--')\n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "        \n",
    "# Scraping Volumes_sold\n",
    "volumes_sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in volumes_sold:\n",
    "    if i.text is None:\n",
    "        Volumes_sold.append('--')\n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in publisher:\n",
    "    if i.text is None:\n",
    "        Publisher.append('--')\n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "        \n",
    "# Scraping Genre\n",
    "genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in genre:\n",
    "    if i.text is None:\n",
    "        Genre.append('--')\n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "\n",
    "Top_selling_book=pd.DataFrame({})\n",
    "Top_selling_book['Book_name']=Book_name\n",
    "Top_selling_book['Author_name']=Author_name\n",
    "Top_selling_book['Volumes_sold']=Volumes_sold\n",
    "Top_selling_book['Publisher']=Publisher\n",
    "Top_selling_book['Genre']=Genre\n",
    "Top_selling_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5e161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d1d33f8",
   "metadata": {},
   "source": [
    "# Question-7"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95645404",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5d79c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5f12ae7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,174,613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,252,359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,032,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>260,404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  2,174,613  \n",
       "1    51 min     8.7  1,252,359  \n",
       "2    44 min     8.1  1,032,903  \n",
       "3    60 min     7.5    303,699  \n",
       "4    43 min     7.6    262,848  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,984  \n",
       "96   50 min     7.8     64,014  \n",
       "97   42 min     8.1    208,614  \n",
       "98   45 min       7     43,410  \n",
       "99  572 min     8.6    260,404  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating empty list\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "#Scraping Name\n",
    "name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Year_span\n",
    "year_span=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "for i in year_span:\n",
    "    Year_span.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping Genre\n",
    "genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Run_time\n",
    "run_time=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "for i in run_time:\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping Ratings\n",
    "ratings=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]')\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping Votes\n",
    "votes=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"][3]/span[2]')\n",
    "for i in votes:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "Top_shows=pd.DataFrame({})\n",
    "Top_shows['Name']=Name\n",
    "Top_shows['Year_span']=Year_span\n",
    "Top_shows['Genre']=Genre\n",
    "Top_shows['Run_time']=Run_time\n",
    "Top_shows['Ratings']=Ratings\n",
    "Top_shows['Votes']=Votes\n",
    "Top_shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9477d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c1d7102",
   "metadata": {},
   "source": [
    "# Question-8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8902d1f8",
   "metadata": {},
   "source": [
    "8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6eaa751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https://archive.ics.uci.edu/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "844a56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataste= driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "view_dataste.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1b07c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "#scraping Dataset name\n",
    "data_name= driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]/a')\n",
    "for i in data_name[1:]:\n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)\n",
    "\n",
    "time.sleep(4)        \n",
    "#Scraping data Type\n",
    "data_type=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "for i in data_type[1:]:\n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "\n",
    "#Scraping Task\n",
    "task=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "for i in task[1:]:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "        \n",
    "time.sleep(4) \n",
    "                          \n",
    "#Scraping Attribute_type\n",
    "attribute_type=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]/table/tbody/tr/td[2]')\n",
    "for i in attribute_type[1:]:\n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)\n",
    "\n",
    "time.sleep(4)         \n",
    "#Scraping No_of_instances\n",
    "no_of_instances=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "for i in no_of_instances[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)\n",
    "\n",
    "time.sleep(4)         \n",
    "#Scraping No_of_attribute\n",
    "no_of_attribute=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "for i in no_of_attribute[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "#Scraping Year\n",
    "year=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]/table/tbody/tr/td[3]')\n",
    "for i in year[1:]:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "        \n",
    "data_dataset=pd.DataFrame({})\n",
    "data_dataset['Dataset_name']= Dataset_name\n",
    "data_dataset['Data_type']= Data_type\n",
    "data_dataset['Task']= Task\n",
    "data_dataset['Attribute_type']= Attribute_type\n",
    "data_dataset['No_of_instances']= No_of_instances\n",
    "data_dataset['No_of_attribute']= No_of_attribute\n",
    "data_dataset['Year']= Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3e55d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>17 Attributes</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Attributes</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Attributes</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Attributes</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Attributes</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset_name     Data_type            Task  \\\n",
       "0                         Heart Disease  Multivariate  Classification   \n",
       "1                                 Adult  Multivariate  Classification   \n",
       "2                      Dry Bean Dataset  Multivariate  Classification   \n",
       "3                              Diabetes                                 \n",
       "4            Rice (Cammeo and Osmancik)  Multivariate  Classification   \n",
       "5                                  Wine  Multivariate  Classification   \n",
       "6                        Car Evaluation  Multivariate  Classification   \n",
       "7  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "8                              Mushroom  Multivariate  Classification   \n",
       "\n",
       "               Attribute_type   No_of_instances No_of_attribute       Year  \n",
       "0  Categorical, Integer, Real     303 Instances   13 Attributes   7/1/1988  \n",
       "1        Categorical, Integer  48.84K Instances   14 Attributes   5/1/1996  \n",
       "2               Integer, Real  13.61K Instances   17 Attributes  9/14/2020  \n",
       "3        Categorical, Integer                     20 Attributes        N/A  \n",
       "4                        Real   3.81K Instances    8 Attributes  10/6/2019  \n",
       "5               Integer, Real     178 Instances   13 Attributes   7/1/1991  \n",
       "6                 Categorical   1.73K Instances    6 Attributes   6/1/1997  \n",
       "7                        Real     569 Instances   30 Attributes  11/1/1995  \n",
       "8                 Categorical   8.12K Instances   22 Attributes  4/27/1987  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e25797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb2aa8ce",
   "metadata": {},
   "source": [
    "# Question-9"
   ]
  },
  {
   "cell_type": "raw",
   "id": "935cae5d",
   "metadata": {},
   "source": [
    "9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "15756b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url = (\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ab1a2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//input[@class=\"suggestor-input \"]')\n",
    "search.send_keys('Data Science')\n",
    "\n",
    "search_btn=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55626d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b1d32d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills_they_hire</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arbeit Associates</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>SQL\\nPython\\nAnalytics\\nGoogle Analytics\\nData...</td>\n",
       "      <td>Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVE-Promagne Business Solutions</td>\n",
       "      <td>L&amp;D Trainer - Python &amp; Data Science/Data Analy...</td>\n",
       "      <td>Python\\nMachine\\nScience\\nDevelopment\\nMachine...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transunion</td>\n",
       "      <td>Sr Analyst - Data Science and Analytics</td>\n",
       "      <td>Analytics\\nFinance\\nBusiness intelligence\\nQua...</td>\n",
       "      <td>Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.2\\n190 Reviews</td>\n",
       "      <td>Manager/Senior Manager - Data Science</td>\n",
       "      <td>Data Science\\nNatural language processing\\nDat...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Axtria India</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Vision\\nAnalytics\\nDeep Learning\\nNetworking\\n...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.4\\n315 Reviews</td>\n",
       "      <td>Engineer II- Data Science &amp; Analytics</td>\n",
       "      <td>Data Science\\nstatistical modeling\\nmachine le...</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bizongo</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>python\\nnumpy\\nmachine learning\\ntensorflow\\nP...</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka(Electronic City)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5\\n59 Reviews</td>\n",
       "      <td>L&amp;D Trainer - Python &amp; Data Science/Data Analy...</td>\n",
       "      <td>Data Analytics\\nIT training\\nTraining\\nMachine...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Raytheon Technologies</td>\n",
       "      <td>Lead - Data Science - Financial Services</td>\n",
       "      <td>Data Science\\nFinancial services\\nScience\\nDat...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0\\n50 Reviews</td>\n",
       "      <td>Head - Data Science &amp; Analytics - Bank</td>\n",
       "      <td>Data Analytics\\nData Science\\nScience\\nData mo...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Augusta Infotech</td>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Data Science\\nAzure\\nArtificial Intelligence\\n...</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AVE-Promagne Business Solutions</td>\n",
       "      <td>Data Science Manager - Machine Learning/Predic...</td>\n",
       "      <td>Data Science\\nNeural networks\\nDevelopment\\nPr...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dimensions HRD Consultants</td>\n",
       "      <td>Unit Manager - Payments - Data Science/Senior ...</td>\n",
       "      <td>DBMS\\nPython\\nArchitecture\\nData management\\nD...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dimensions HRD Consultants</td>\n",
       "      <td>Sr Programmer - Python / Data Science Developer</td>\n",
       "      <td>Data Modeling\\nPython\\nStatistics\\nData Scienc...</td>\n",
       "      <td>Mumbai, Maharashtra, Mumbai Suburban, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Conneqt Digital</td>\n",
       "      <td>Manager/Sr. Manager - GPS Safety Data Sciences</td>\n",
       "      <td>GPS\\nOperations\\nHealthcare\\nSR\\nDevelopment\\n...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company  \\\n",
       "0                 Arbeit Associates   \n",
       "1   AVE-Promagne Business Solutions   \n",
       "2                        Transunion   \n",
       "3                  4.2\\n190 Reviews   \n",
       "4                      Axtria India   \n",
       "5                  3.4\\n315 Reviews   \n",
       "6                           Bizongo   \n",
       "7                   3.5\\n59 Reviews   \n",
       "8             Raytheon Technologies   \n",
       "9                   4.0\\n50 Reviews   \n",
       "10                 Augusta Infotech   \n",
       "11  AVE-Promagne Business Solutions   \n",
       "12       Dimensions HRD Consultants   \n",
       "13       Dimensions HRD Consultants   \n",
       "14                  Conneqt Digital   \n",
       "\n",
       "                                          Designation  \\\n",
       "0                               Data Science Engineer   \n",
       "1   L&D Trainer - Python & Data Science/Data Analy...   \n",
       "2             Sr Analyst - Data Science and Analytics   \n",
       "3               Manager/Senior Manager - Data Science   \n",
       "4                               Data Science Engineer   \n",
       "5               Engineer II- Data Science & Analytics   \n",
       "6                               Data Science Engineer   \n",
       "7   L&D Trainer - Python & Data Science/Data Analy...   \n",
       "8            Lead - Data Science - Financial Services   \n",
       "9              Head - Data Science & Analytics - Bank   \n",
       "10                              Data Science Engineer   \n",
       "11  Data Science Manager - Machine Learning/Predic...   \n",
       "12  Unit Manager - Payments - Data Science/Senior ...   \n",
       "13    Sr Programmer - Python / Data Science Developer   \n",
       "14     Manager/Sr. Manager - GPS Safety Data Sciences   \n",
       "\n",
       "                                     Skills_they_hire  \\\n",
       "0   SQL\\nPython\\nAnalytics\\nGoogle Analytics\\nData...   \n",
       "1   Python\\nMachine\\nScience\\nDevelopment\\nMachine...   \n",
       "2   Analytics\\nFinance\\nBusiness intelligence\\nQua...   \n",
       "3   Data Science\\nNatural language processing\\nDat...   \n",
       "4   Vision\\nAnalytics\\nDeep Learning\\nNetworking\\n...   \n",
       "5   Data Science\\nstatistical modeling\\nmachine le...   \n",
       "6   python\\nnumpy\\nmachine learning\\ntensorflow\\nP...   \n",
       "7   Data Analytics\\nIT training\\nTraining\\nMachine...   \n",
       "8   Data Science\\nFinancial services\\nScience\\nDat...   \n",
       "9   Data Analytics\\nData Science\\nScience\\nData mo...   \n",
       "10  Data Science\\nAzure\\nArtificial Intelligence\\n...   \n",
       "11  Data Science\\nNeural networks\\nDevelopment\\nPr...   \n",
       "12  DBMS\\nPython\\nArchitecture\\nData management\\nD...   \n",
       "13  Data Modeling\\nPython\\nStatistics\\nData Scienc...   \n",
       "14  GPS\\nOperations\\nHealthcare\\nSR\\nDevelopment\\n...   \n",
       "\n",
       "                                             Location  \n",
       "0   Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...  \n",
       "1   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  \n",
       "2                                       Pune, Chennai  \n",
       "3   Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5   Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...  \n",
       "6    Bangalore/ Bengaluru, Karnataka(Electronic City)  \n",
       "7   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  \n",
       "8                                    Gurgaon/Gurugram  \n",
       "9                                    Gurgaon/Gurugram  \n",
       "10                       Hybrid - Bangalore/Bengaluru  \n",
       "11                                Bangalore/Bengaluru  \n",
       "12                                               Pune  \n",
       "13  Mumbai, Maharashtra, Mumbai Suburban, Maharashtra  \n",
       "14                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating emepty list\n",
    "\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire=[]\n",
    "Location=[]\n",
    "\n",
    "#Scraping Company \n",
    "company=driver.find_elements(By.XPATH,'//div[@class=\"companyInfo subheading\"]/a')\n",
    "for i  in company[0:15]:\n",
    "    Company.append(i.text)  \n",
    "    \n",
    "#Scraping Designation \n",
    "designation=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i  in designation[0:15]:\n",
    "    Designation.append(i.text)    \n",
    "     \n",
    "    \n",
    "#Scraping Skills_they_hire \n",
    "skills_they_hire=driver.find_elements(By.XPATH,'//ul[@class=\"tags has-description\"]')\n",
    "for i  in skills_they_hire[0:15]:\n",
    "    Skills_they_hire.append(i.text)\n",
    "    \n",
    "\n",
    "    \n",
    "#Scraping Location \n",
    "location=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i  in location[0:15]:\n",
    "    if i.text is None:\n",
    "        \n",
    "        Location.append('--')\n",
    "    else:\n",
    "        Location.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "Recruiters=pd.DataFrame({})\n",
    "Recruiters['Company']= Company\n",
    "Recruiters['Designation']= Designation\n",
    "Recruiters['Skills_they_hire']= Skills_they_hire\n",
    "Recruiters['Location']= Location\n",
    "Recruiters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d6201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f3c671",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515cb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
